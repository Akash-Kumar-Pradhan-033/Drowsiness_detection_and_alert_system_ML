{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282df798-57b6-423e-a078-958c073d3801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.108-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ommak\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in c:\\users\\ommak\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ommak\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (76.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ommak\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Downloading ultralytics-8.3.108-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 974.8/974.8 kB 11.3 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.108 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f3797-d501-401d-be41-8a3cf40a2e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Total samples: 60033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ommak\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths to datasets\n",
    "ddd_path = r\"C:\\Users\\ommak\\Drowsiness detection and alert system\\Data\\Driver Drowsiness Dataset (DDD)\"\n",
    "fi_path = r\"C:\\Users\\ommak\\Drowsiness detection and alert system\\Data\\0 FaceImages\"\n",
    "fi1_path = r\"C:\\Users\\ommak\\Drowsiness detection and alert system\\Data\\0 FaceImages 1\"\n",
    "\n",
    "# Enhanced CNN Model with Dropout and BatchNorm\n",
    "class DrowsinessClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrowsinessClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)  # 2 classes: drowsy/not-drowsy\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Enhanced Dataset class with data balancing\n",
    "class DrowsinessDataset(Dataset):\n",
    "    def __init__(self, dataset_path, transform=None, balance_classes=True):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(dataset_path) \n",
    "                            if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "        self.images, self.labels = self.load_data(balance_classes)\n",
    "\n",
    "    def load_data(self, balance_classes):\n",
    "        images = []\n",
    "        labels = []\n",
    "        class_counts = {}\n",
    "        \n",
    "        # First pass to count samples per class\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(self.dataset_path, class_name)\n",
    "            class_counts[label] = len(os.listdir(class_path))\n",
    "        \n",
    "        max_samples = max(class_counts.values()) if balance_classes else None\n",
    "        \n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(self.dataset_path, class_name)\n",
    "            samples = []\n",
    "            \n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if image is None:\n",
    "                        continue\n",
    "                    image = cv2.resize(image, (64, 64))\n",
    "                    samples.append(image)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {image_path}: {e}\")\n",
    "            \n",
    "            # Apply class balancing if requested\n",
    "            if balance_classes and len(samples) > max_samples:\n",
    "                samples = samples[:max_samples]\n",
    "            \n",
    "            images.extend(samples)\n",
    "            labels.extend([label] * len(samples))\n",
    "        \n",
    "        return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Advanced data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.3),\n",
    "])\n",
    "\n",
    "# Load datasets with class balancing\n",
    "print(\"Loading datasets...\")\n",
    "try:\n",
    "    ddd_dataset = DrowsinessDataset(ddd_path, transform=transform, balance_classes=True)\n",
    "    fi_dataset = DrowsinessDataset(fi_path, transform=transform, balance_classes=True)\n",
    "    fi1_dataset = DrowsinessDataset(fi1_path, transform=transform, balance_classes=True)\n",
    "    combined_dataset = torch.utils.data.ConcatDataset([ddd_dataset, fi_dataset, fi1_dataset])\n",
    "    print(f\"Total samples: {len(combined_dataset)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Split into train/val with stratification\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(combined_dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=[label for _, label in combined_dataset]\n",
    ")\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(combined_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(combined_dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize model with better initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model = DrowsinessClassifier().to(device)\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Improved optimizer with learning rate scheduling\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "\n",
    "# Training loop with enhanced metrics\n",
    "print(\"Training classifier...\")\n",
    "for epoch in range(30):  # Increased max epochs\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Ensure input has channel dimension\n",
    "        if inputs.dim() == 3:\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if inputs.dim() == 3:\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss/len(val_loader))\n",
    "    \n",
    "    # Early stopping check\n",
    "    current_val_loss = val_loss/len(val_loader)\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_drowsiness_model.pth\")\n",
    "        print(f\"New best model saved with val loss: {best_val_loss:.4f}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss/len(train_loader):.4f} | Acc: {100*train_correct/train_total:.2f}%\")\n",
    "    print(f\"Val Loss: {current_val_loss:.4f} | Acc: {100*val_correct/val_total:.2f}%\")\n",
    "    print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if no_improve >= patience:\n",
    "        print(f\"Early stopping after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete. Best model saved to best_drowsiness_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc12c5d-9cfc-44e7-a3ab-87cd940a45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
